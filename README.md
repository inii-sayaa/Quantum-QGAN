# ğŸŒŒ Quantum-QGAN: Hybrid Quantum-Classical Generative Adversarial Network

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![PennyLane](https://img.shields.io/badge/PennyLane-Quantum-green.svg)](https://pennylane.ai/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A **hybrid quantum-classical Generative Adversarial Network (GAN)** implementation that combines:
- ğŸ”¬ **Quantum Generator**: Variational Quantum Circuit (VQC) using PennyLane
- ğŸ§  **Classical Discriminator**: Multi-layer Perceptron (MLP) using PyTorch
- ğŸ“Š **Advanced Metrics**: Maximum Mean Discrepancy (MMD) for distribution comparison

This project demonstrates how quantum computing can be integrated into modern machine learning workflows for generative modeling tasks.

---

## ğŸš€ Features

- âœ… **Hybrid Architecture**: Quantum generator + Classical discriminator
- âœ… **Flexible Configuration**: Easy-to-modify hyperparameters
- âœ… **Professional Structure**: Modular, maintainable, and scalable codebase
- âœ… **Rich Visualizations**: Training dynamics and distribution analysis
- âœ… **Reproducibility**: Seed management for consistent results
- âœ… **Model Checkpointing**: Save and resume training

---

## ğŸ“ Project Structure

```
QGAN-QUANTUM/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                    # Main entry point
â”œâ”€â”€ ğŸ“„ requirements.txt           # Dependencies
â”œâ”€â”€ ğŸ“„ STRUCTURE.md              # Detailed structure guide
â”‚
â”œâ”€â”€ ğŸ“ src/                       # Source code
â”‚   â”œâ”€â”€ config.py                 # Configuration settings
â”‚   â”œâ”€â”€ models.py                 # Quantum & Classical models
â”‚   â”œâ”€â”€ training.py               # Training pipeline
â”‚   â”œâ”€â”€ visualization.py          # Plotting functions
â”‚   â””â”€â”€ utils.py                  # Utility functions
â”‚
â”œâ”€â”€ ğŸ“ data/                      # Data directory
â”œâ”€â”€ ğŸ“ output/                    # Results & checkpoints
â”‚   â”œâ”€â”€ qgan_analysis.png         # Training plots
â”‚   â”œâ”€â”€ qgan_enhanced.png         # Enhanced visualization
â”‚   â””â”€â”€ qgan_checkpoint.pth       # Model checkpoint
â”‚
â””â”€â”€ ğŸ“ venv/                      # Virtual environment
```

See [STRUCTURE.md](STRUCTURE.md) for detailed architecture documentation.

---

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/inii-sayaa/Quantum-QGAN.git
   cd Quantum-QGAN
   ```

2. **Create virtual environment** (recommended)
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ¯ Quick Start

### Basic Training

Run with default configuration:
```bash
python main.py
```

This will:
1. Initialize a 2-qubit quantum generator
2. Train for 300 epochs on CPU
3. Generate visualization plots
4. Save model checkpoint

### Configuration

Modify hyperparameters in `main.py`:

```python
CONFIG = get_default_config()

# Adjust settings
CONFIG["n_qubits"] = 3          # Number of qubits
CONFIG["num_epochs"] = 500      # Training epochs
CONFIG["batch_size"] = 64       # Batch size
CONFIG["lr_gen"] = 0.01         # Generator learning rate
CONFIG["lr_disc"] = 0.001       # Discriminator learning rate
CONFIG["device"] = "cuda"       # Use GPU (if available)
```

---

## ğŸ“Š Outputs

After training, you'll find:

### 1. **Training Analysis** (`output/qgan_analysis.png`)
- Loss curves (Generator & Discriminator)
- MMD metric over time
- Sample distribution comparison
- Training statistics

### 2. **Enhanced Visualization** (`output/qgan_enhanced.png`)
- Distribution heatmaps
- Quantum circuit diagram
- Convergence analysis
- Advanced metrics

### 3. **Model Checkpoint** (`output/qgan_checkpoint.pth`)
- Trained generator state
- Trained discriminator state
- Configuration snapshot
- Training history

---

## ğŸ§ª How It Works

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Quantum GAN Training Loop              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  1. Noise Input (Latent Vector)                â”‚
â”‚           â†“                                     â”‚
â”‚  2. Quantum Generator (VQC)                    â”‚
â”‚           â†“                                     â”‚
â”‚  3. Generated Samples                          â”‚
â”‚           â†“                                     â”‚
â”‚  4. Classical Discriminator (MLP)              â”‚
â”‚           â†“                                     â”‚
â”‚  5. Real/Fake Classification                   â”‚
â”‚           â†“                                     â”‚
â”‚  6. Adversarial Loss & Backpropagation         â”‚
â”‚           â†“                                     â”‚
â”‚  7. Parameter Updates                          â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quantum Generator
- **Variational Quantum Circuit (VQC)** with parameterized gates
- Encodes classical noise into quantum states
- Implements quantum rotations and entanglement
- Outputs generated samples via measurement

### Classical Discriminator
- **Multi-Layer Perceptron (MLP)** with batch normalization
- Distinguishes real data from generated samples
- Standard adversarial training objective

---

## ğŸ“ˆ Key Metrics

- **Generator Loss**: Measures generator's ability to fool discriminator
- **Discriminator Loss**: Measures discriminator's classification accuracy
- **MMD (Maximum Mean Discrepancy)**: Distribution similarity metric
- **Mean/Std Difference**: Statistical comparison of distributions

---

## ğŸ”§ Advanced Usage

### Resuming Training

Load a previous checkpoint:
```python
checkpoint = torch.load("output/qgan_checkpoint.pth")
generator.load_state_dict(checkpoint['generator_state_dict'])
discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
```

### Custom Data Distribution

Modify target distribution in `src/utils.py`:
```python
def sample_real_data(n_samples, config):
    # Your custom data distribution
    return custom_data
```

---

## ğŸ“ Learning Resources

### Quantum Computing
- [PennyLane Documentation](https://pennylane.ai/)
- [Quantum Machine Learning](https://pennylane.ai/qml/)

### GANs
- [GAN Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)
- [Original GAN Paper](https://arxiv.org/abs/1406.2661)

### Hybrid Quantum-Classical ML
- [Quantum GANs](https://arxiv.org/abs/1804.08641)
- [Variational Quantum Algorithms](https://arxiv.org/abs/2012.09265)

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to:
- Report bugs
- Suggest features
- Submit pull requests

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

- **PennyLane**: Quantum computing framework
- **PyTorch**: Deep learning framework
- **Quantum Computing Community**: Research and inspiration

---

## ğŸ“§ Contact

**Author**: [Your Name]  
**GitHub**: [@inii-sayaa](https://github.com/inii-sayaa)  
**Project**: [Quantum-QGAN](https://github.com/inii-sayaa/Quantum-QGAN)

---

## ğŸŒŸ Star History

If you find this project useful, please consider giving it a star â­!

---

*Built with ğŸ’œ using Quantum Computing and Machine Learning*
